{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ae794ee",
   "metadata": {},
   "source": [
    "# Implementing Feedforward Neural Networks with TesorFlow - Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62521a3d",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/AnwarMirza/CPS2025/blob/main/FNNwithTFKeras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/AnwarMirza/CPS2025/blob/main/FNNwithTFKeras.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c227c6e",
   "metadata": {},
   "source": [
    "<!-- \n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AnwarMirza/CPS2025/blob/main/FNNwithTFKeras.ipynb)\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "623d8efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "Keras version: 3.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Print the versions of TensorFlow and Keras\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b895ad6",
   "metadata": {},
   "source": [
    "## Building an Image Classifier Using the Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497f245b",
   "metadata": {},
   "source": [
    "Load Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "906647be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_full.shape = (60000, 28, 28), X_train_full.dtype = uint8\n",
      "X_test.shape = (10000, 28, 28), X_test.dtype = uint8\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# print shapes of training and testing data\n",
    "print(f'X_train_full.shape = {X_train_full.shape}, X_train_full.dtype = {X_train_full.dtype}')\n",
    "print(f'X_test.shape = {X_test.shape}, X_test.dtype = {X_test.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11da2fc",
   "metadata": {},
   "source": [
    "We create the Keras model using the sequential API. This is the simplest of the Keras models for neural networks and is made up of a single stack of layers connected sequentially.\n",
    "\n",
    "Within this sequential model we have:\n",
    "* One `Flatten` layer that converts each input image (of size $28\\times 28$) into a 1D array: if it receives the input data `X`, it computes `X.reshape(-1, 1)`. \n",
    "    * This layer does some simple preprocessing, involving only the shape of the input instances.\n",
    "    * It does not involve the batch size.\n",
    "    * Another way to replace this `Flatten` layer is to use `keras.layers.InputLayer` as the first layer, setting the `input_shape=[28,28]`.\n",
    "* One `Dense` hidden layer with 300 neurons: \n",
    "    * Each neuron in this layer is connected with each neuron in the previous (i.e., input) layer.\n",
    "    * Each neuron in this layer also receives a connection from a unit bias (thus resulting into 300 bias weights).\n",
    "    * Each neurn in this layer uses ReLU as the activation function.\n",
    "* One `Dense` hidden layer with 100 neurons:\n",
    "    * Each neuron is connected with each neuron in the previous (dense layer). Thus resulting into $300\\times 100$ weights.\n",
    "    * Each neuron also receives a connection from a unit bias (resulting into 100 bias weights).\n",
    "    * ReLU is used by each neuron as an activation function.\n",
    "* One `Dense` output layer with 10 neurons:\n",
    "    * Each neuron is connected with every neuron in the previous layer (resulting into $100\\times 10$ weights).\n",
    "    * Each neuron also receives a connection from a unit bias (resulting into $10$ bias weights).\n",
    "    * The activation function for each neuron is `softmax`.\n",
    "    * The number of neurons in this layer is equal to the number of output classes (which is 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49ebc341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    # keras.layers.Input(shape=[28, 28]),\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed764f6",
   "metadata": {},
   "source": [
    "> An alternate way to make this model is as follows:\n",
    "> \n",
    "    > ```python\n",
    "    > model = keras.models.Sequential()\n",
    "    > model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "    > model.add(keras.layers.Dense(300, activation='relu'))\n",
    "    > model.add(keras.layers.Dense(100, activation='relu'))\n",
    "    > model.add(keras.layers.Dense(10, activation='relu'))\n",
    "    >```\n",
    "> \n",
    "> In this case, after creating a sequential model, each layer is added to it in each preceeding line of the code.  \n",
    ">\n",
    "> Each layer has been added sequentially to the model object. The activation function used in the dense layers is ReLU. This can be specified like this as well:  \n",
    "> ```python\n",
    "> model.add(keras.layers.Dense(100, activation=activation.relu))\n",
    "> ```\n",
    ">\n",
    "> This single line can also be written as  \n",
    ">```python\n",
    "> model.add(layers.Dense(100))\n",
    "> model.add(layers.Activation(activation.relu))\n",
    ">```\n",
    ">\n",
    "> Here the activation function for the layer has been specified separately in the layer addition layer right after specifying the `Dense` layer.\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549bfaca",
   "metadata": {},
   "source": [
    "There are several activation functions available in Keras. The full list is available at [https://keras.io/activations](https://keras.io/activations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8ee2e6",
   "metadata": {},
   "source": [
    "<table cellspacing=\"0\" cellpadding=\"0\" border=\"0\" width=\"60%\" align=\"center\">\n",
    "  <tr>\n",
    "    <th valign=\"middle\" align=\"center\" width=\"125\" bgcolor=\"#DDDDDD\">\n",
    "    Using Examples of Code from the keras.io Site\n",
    "    </th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"line-height:1.6;padding: 5px 15px;\">\n",
    "      <div>Example of code from the keras.io site work as they are with tf.keras, however, the import statements need to be changed. For example, lets have the following code from keras.io:</div>\n",
    "      <pre>\n",
    "        from keras.layers import Dense\n",
    "        output_layer = Dense(10)</pre>\n",
    "      <div>We must change it to</div>\n",
    "      <pre>\n",
    "        from tensorflow.keras.layers import Dense\n",
    "        output_layer = Dense(10)</pre>\n",
    "      <div>Or, we can simply use the full paths,</div>\n",
    "      <pre>\n",
    "        from tensorflow import keras\n",
    "        output_layer = keras.layers.Dense(10)</pre>\n",
    "      <div></div>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0c997fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
